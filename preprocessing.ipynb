{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, TextDataset, DataCollatorForLanguageModeling, Trainer, TrainingArguments, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/medium_articles.csv\")\n",
    "#df = df[0:100]\n",
    "df[\"title\"] = df[\"title\"].astype(str)\n",
    "df[\"text\"] = df[\"text\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_title_text(row):\n",
    "    return \"[TITLE]\\n\" + row[\"title\"] + \"\\n[/TITLE]\\n\" + row[\"text\"] + \"\\n\\n\"\n",
    "\n",
    "combined_text =  df.apply(combine_title_text, axis=1).str.cat(sep=\"\")\n",
    "\n",
    "with open(\"data/training_data.txt\", \"w\") as f:\n",
    "    f.write(combined_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "c:\\Users\\Jared\\anaconda3\\envs\\fastapi\\Lib\\site-packages\\transformers\\data\\datasets\\language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"./model/custom-gpt2-tokenizer\")\n",
    "dataset = TextDataset(\n",
    "    tokenizer=tokenizer,\n",
    "    block_size=512,\n",
    "    file_path=\"./data/training_data.txt\"\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jared\\anaconda3\\envs\\fastapi\\Lib\\site-packages\\accelerate\\accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"./model/custom-gpt2-model\"\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    save_steps=50\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 171/171 [00:36<00:00,  4.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 36.3006, 'train_samples_per_second': 18.677, 'train_steps_per_second': 4.711, 'train_loss': 5.276577062774122, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "model.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"./model/custom-gpt2-model-1024\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "input_text = \"[TITLE] An Overview of AI [/TITLE]\"\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
    "with torch.no_grad():\n",
    "    output_sequences = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        max_length=250,\n",
    "        do_sample=True,\n",
    "        top_k=30,\n",
    "        early_stopping=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TITLE] An Overview of AI [/TITLE]\n",
      "\n",
      "Introduction of AI (AI) and Artificial Intelligence (AI) is an emerging field of theoretical, empirical and applied research, especially in relation to the field of artificial intelligence. These fields of research involve artificial intelligence, machine learning, neuroscience, and biological sciences.\n",
      "\n",
      "In AI studies, the field of AI is comprised of researchers who have taken part in the development of data-driven processes, including machine vision, data interpretation, cognitive neuroscience, computational neuroscience, behavioral neuroscience, and cognitive neuroscience.\n",
      "\n",
      "The field of AI is characterized by three main areas of research:\n",
      "\n",
      "1. A methodical approach to the analysis of data:\n",
      "\n",
      "2. A theoretical model of AI\n",
      "\n",
      "3. The model of AI is a theoretical model of artificial intelligence, which describes how AI might operate, or not, in accordance with the theoretical models of AI.\n",
      "\n",
      "The most recent contribution of AI to the research and publication of theoretical AI articles was published by Stanford University (2013), by the University of Michigan and Stanford Medical University (2016). In this paper, Artificial Intelligence and Machine Learning: A Theory\n",
      "\n",
      "Researchers from Stanford University, Michigan, and Stanford Medical University participated in the research on a theoretical model\n"
     ]
    }
   ],
   "source": [
    "generated_text = tokenizer.decode(output_sequences[0], skip_special_tokens=True) \n",
    "print(generated_text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "input_text = \"[TITLE] A Note to myself on friends[/TITLE]\"\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
    "output_sequences = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    max_length=1000,\n",
    "    do_sample=True,\n",
    "    top_k=50,\n",
    "    early_stopping=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TITLE] A Note to myself on friends[/TITLE]\n",
      "\n",
      "These are just some of the things that I learned during my time with The Mindfulness Journey. If you are interested in the life-changing experience of The Mindfulness Journey, please visit our guide to mindfulness and how-to book. If you enjoy the writing of this post, please consider following us on Instagram for daily highlights and inspiration. Please follow the blog on Facebook as well for helpful notifications when you have time.\n",
      "\n",
      "The Mindfulness Journey\n",
      "\n",
      "â€œThe Mindfulness Journeyâ€œ\n",
      "\n",
      "What is mindfulness? How does it relate to human nature?\n",
      "\n",
      "Most people confuse mindfulness with self-regulation. So the question is not how much you can maintain your mindfulness or how often you should train yourself to maintain it. It is what exactly does mindfulness do to you?\n",
      "\n",
      "â€œHow You Canâ€™t Use Up All Youâ€™s Mental Energy in a Non-Heterothetical Way\n",
      "\n",
      "If you are the kind of person who just wants to focus on things and see the things, why not have a little mindfulness while you do this?\n",
      "\n",
      "â€œA Guide to How to Use Up All Youâ€™s Money in One Medium\n",
      "\n",
      "How to Make Money\n",
      "\n",
      "Why Use Money?\n",
      "\n",
      "Itâ€™s not that easy. Youâ€™ll have to manage the money quickly, just pay attention. Then it will pay for itself. But if you work hard enough youâ€™ll make it.\n",
      "\n",
      "â€\n",
      "\n",
      "Lately, Iâ€™m wondering how much money Iâ€™ll have in my pocket!â€\n",
      "\n",
      "â€\n",
      "\n",
      "Life is not great without spending. But how is it worth investing?\n",
      "\n",
      "When you invest on happiness â€” or not â€” youâ€™ll have to buy a lottery ticket.\n",
      "\n",
      "â€\n",
      "\n",
      "â€\n",
      "\n",
      "No, I donâ€™t think we should be talking about everything we spend on ourselves.â€\n",
      "\n",
      "A Note on Saving\n",
      "\n",
      "If you want to be a good student and get out of your comfort zone, itâ€™s important that you keep your mind open.\n",
      "\n",
      "â€\n",
      "\n",
      "I want to make myself feel good. I want to feel good about myself or about everyone else.â€\n",
      "\n",
      "â€\n",
      "\n",
      "Donâ€™t forget to keep an eye on your financial resources when you choose to do so.\n",
      "\n",
      "â€\n",
      "\n",
      "The Mindfulness Journey will help you\n",
      "\n",
      "Youâ€™ll become one more person you trust, more responsible for your finances and more aware of yourself.\n",
      "\n",
      "â€\n",
      "\n",
      "For more from Mindfulness Journey, check out my free weekly Mindfulness Guide â€“ a guide to learning how to improve your mindfulness.\n",
      "\n",
      "â€\n",
      "\n",
      "Please share this article if you love learning and taking part in this free weekly edition of Mindfulness Journey. If you like it, make sure you follow along with this page.\n",
      "\n",
      "Read Next: How To Write A Better Living Partner In Less Than 24hrs. The Mind mindfulness course covers all aspects of creating great relationships and fulfilling their goals.\n",
      "\n",
      "â€\n",
      "\n",
      "If you liked this post, follow me on Medium. Read my articles on YouTube, Facebook, Instagram, Google Plus and my Weekly Mindfulness Guide.\n",
      "\n",
      "Related\n",
      "\n",
      "You might also like:\n",
      "\n",
      "What is yoga?\n",
      "\n",
      "How To Become A Great Mindfulness Master\n",
      "\n",
      "How To Build A Good Relationship\n",
      "\n",
      "What Is The Mindfulness Journey?\n",
      "\n",
      "My Mindfulness Journey To Be a Better Living Partnership\n",
      "\n",
      "How To Change Your Mindfulness\n",
      "\n",
      "How To Become A Great Mindfulness Master\n",
      "\n",
      "The Mindfulness Journey Course\n",
      "More Content From Mindfulness Journey\n"
     ]
    }
   ],
   "source": [
    "generated_text = tokenizer.decode(output_sequences[0], skip_special_tokens=True) \n",
    "print(generated_text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[   58, 49560,  2538,    60,  1052, 28578,   286,  9552, 46581, 49560,\n",
      "          2538,    60]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[TITLE] An Overview of AI [/TITLE]\n",
      "\n",
      "A list of things you can do with AI in Java EE.\n",
      "\n",
      "Use AI to run the various components of your application, so that your users don't need to write code twice a day. Using AI when you're just starting out should make your code easier (see also a great article about how to use AI in JRE).\n",
      "\n",
      "Automate building AI scripts.\n",
      "\n",
      "Using AI in AI helps you write smarter code.\n",
      "\n",
      "Learn about the various ways AI can help you perform your projects.\n",
      "\n",
      "Develop, develop and test automated script-based applications.\n",
      "\n",
      "Learn about what's in your software that could be deployed using AI using your application.\n",
      "\n",
      "Learn about tools you have available to automate tasks in your application.\n",
      "\n",
      "Learn about features you can add functionality from your code in a way you wouldn't normally do.\n",
      "\n",
      "If you think you know how to write AI in Java EE, or other programming languages, we would like to hear what you think. Leave a comment below below!\n",
      "\n",
      "[AUTHENTICATION]\n",
      "\n",
      "I am a professional Java developer and programmer who builds Java EE code. I have worked on numerous projects such as the Java EE Spring Project, Java EE 5.0 and Java EE 8.\n",
      "\n",
      "When writing code for the web, it's usually much more difficult to figure out how to use a framework like Scala. I've used Scala on everything I want to do on my site. It's not only amazing, it's also more useful.\n",
      "\n",
      "I've used Scala at JRE since I was 8 or 9. It's fast, has very clean and is the equivalent of a Java compiler for code you'd like to do. I have run various types of code as well, but mostly I've used Java's JDBC framework, which lets you use many different types of code. I've used JDBC for a while, and it doesn't provide the features you'll need. So, I just think that this is a good way to spend a lot of time. If we used Java EE as an introduction or a reference to other languages, and Java EE did what I was going for, I would also really like to learn Java EE, but I'm not very confident as a programmer. That's why I chose this way of doing things. Here's an example example of a tool I use to write a simple XML application from scratch. In this example, there are 15 lines of code which is used multiple times to generate JSON from a request for a website. Once the last line is processed, you can use this XML application to build your website. Then, I can go and do all of this logic of the XML server in front of me. That's how I make my website.\n",
      "\n",
      "If you are considering using Java EE, please read about this project and learn how there are many of the most interesting places to learn Java EE. For Java EE's documentation, please check out JH8's Java EE Web Reference.\n",
      "\n",
      "[BACKGROUND]\n",
      "\n",
      "What are the different types of code you see in other frameworks? We could go into what they are, what they don't, but I am using Java EE for this purpose. I was curious to read how some of the different types of code in Java EE operate with each other in different ways. What is your experience on how to use them and how their performance differs between different frameworks?\n",
      "\n",
      "We have been working on Java EE since 2009.\n",
      "\n",
      "[MATCHBACK]\n",
      "\n",
      "What is the difference between JRE (Java Runtime Environment), JRE5, and JRE6? We're not going to talk about JRE (Java Runtime Environment), but JRE is our framework so you should have it, too. If you want to write Java EE or JRE1, you will need it.\n",
      "\n",
      "It's easy to write JRE (Java Runtime Environment), JRE, and JRE6, but how does it perform? It looks the same and is quite the different. It's a huge difference.\n",
      "\n",
      "The difference between JRE, JRE5, and JRE6 starts from the base JRE framework, with basic usage. JRE is where Java EE uses JRE5, like Java EE 6, JRE5 2 and JRE5. The difference between these frameworks is the JRE runtime, which is built directly from the JRE base and is not statically compiled. JRE comes from a JDJ runtime called javac.java.\n",
      "\n",
      "JRE is a lot like C++ and Python, they are built from C. The JRE runtime uses the JRE framework that is used internally by JRE 3. Java EE and Java EE 6 will use different runtime sources that differ the most in each approach. JRE was originally built and optimized for J\n"
     ]
    }
   ],
   "source": [
    "baseline_tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "baseline_model = AutoModelForCausalLM.from_pretrained(\"gpt2\", pad_token_id=baseline_tokenizer.eos_token_id)\n",
    "baseline_model_inputs = baseline_tokenizer(\"[TITLE] An Overview of AI [/TITLE]\", return_tensors=\"pt\")\n",
    "print(baseline_model_inputs)\n",
    "output_sequences = baseline_model.generate(\n",
    "    **baseline_model_inputs,\n",
    "    pad_token_id=baseline_tokenizer.pad_token_id,\n",
    "    max_length=1000,\n",
    "    do_sample=True,\n",
    "    top_k=50,\n",
    "    early_stopping=True,\n",
    ")\n",
    "\n",
    "print(\"Output:\\n\" + 100 * \"-\")\n",
    "print(tokenizer.decode(output_sequences[0], skip_special_tokens=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastapi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
